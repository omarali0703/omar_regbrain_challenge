{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Omar Ali's Cube Submission\n",
        "\n",
        "## Introduction âš“\n",
        "> I have chosen to go with the route of pre-parsing text for analysis using Rhetorical Structure Theory (RST). RST is a theory within text analysis I worked very closely with, that allows you to abstract text in a hierarchical fashion. This is done using a three stage process (Segmenting, Relationship generation and Tree generation). For the consideration of time, a well known RST parser (HILDA) will be used to carry our these stages. As the parser's implementation is fairly old, It has been contained by a wrapper using Docker. Therefore, I will preparse the text I will use in this work and output the findings into a folder for use in this Notebook. Streamlining this process will be explored at the end of this submission with further-work and improvements also explained.\n",
        "\n",
        "## Goal â­\n",
        "> Overall, the main goal of my submission is to understand the language and structure that goes into Policy-definining documents. I will do so by creating a subset of the data for use in RST parsing. This will allow me to weight them and take the most important for use in training a transformer for binary classification. *Less important information taken from the dataset (Not related to policy enforcing) will be used as the second class.*\n",
        "\n",
        "## Overview of Implementation ðŸ•µ\n",
        "\n",
        "> For the consideration of time, I have pre-generated RST trees from a selection of instances within the provided dataset. In practice this would be scaled up to an automated generation cycle per instance whereby, for each instance added to the database, and RST tree would be generated.\n",
        "> \n",
        "> For each instance, the RST tree would be weighted with the most important parts considered highly above the less important sections. Following a similar model to text summarisation, the least important aspects will be removed.\n",
        "> \n",
        "> With the most important parts identified we can train a model to determine what features are present within topics that are indicative of emerging changes required by policymakers. This model allows for our analysis to be scaled to different instances that are coming through every day. \n",
        "> \n",
        "> The hypothesis is that there is some level of consistency within information indicative of a policy change. I hope that the added level of rhetorical structure theory and its segmentation will allow for these parts to be highlighted and learned from.\n",
        "> \n",
        "> In future, I may also consider using the relationships between spans of text as an indication to emerging policies. For example relationships that represent attributions or cause-and-effect might likely be an indication of emerging changes to policy.\n",
        "\n",
        "## Implementation\n",
        "1. Weighting logic to rank our RST trees\n",
        "2. Data taken from the data set processes using HILDA (and RST parser)\n",
        "\n",
        "Output:\n",
        "1. Ranked, indexed list of the most important, salient points taken from the text that are likely to indicate policy changes."
      ],
      "metadata": {
        "id": "k3KZ4rFOwvnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing dependencies needed"
      ],
      "metadata": {
        "id": "dVdOXx3dx-3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "E7U-uUkjx8N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting Text From the Embedded HTML\n",
        "This code snippet is used to extract text taken from the smaller dataset created. For clarity, this dataset included Policy related items. The outputs from the data are parsed using the RST parser. This is done outside of the notebook as I dodn't have enough time to create an implementation of the parser such that it was entirely self contained."
      ],
      "metadata": {
        "id": "geo8LNOqAcpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import csv\n",
        "import gspread\n",
        "import pandas as pd\n",
        "# Authorisation for google to access the data.\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "worksheet = gc.open('cube_smaller_dataset_policy_learning').sheet1\n",
        "rows = worksheet.get_all_values()\n",
        "cube_policy_data_raw = pd.DataFrame.from_records(rows, columns=['issurance_type', 'text'])\n",
        "\n",
        "\n",
        "# Reading the data "
      ],
      "metadata": {
        "id": "GCbopZN-GbMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â RST Ranker Logic\n",
        "This Section of the code aims to rank EDUs based on their importance with the text. Text must first be processed using HILDA and stored."
      ],
      "metadata": {
        "id": "rfxmWGh7xn9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isn0BXdooUgk"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import re \n",
        "import json\n",
        "def convert_str_RST_to_tup(rst_str = None):\n",
        "    rst_str = rst_str.replace('ParseTree', '')\n",
        "    print (rst_str)\n",
        "    rst_str = eval(rst_str)\n",
        "    return rst_str\n",
        "\n",
        "w = []\n",
        "# The two weighting schemes defined. HEAVY removes all SATELITES\n",
        "# (think text summerization), LIGHT only intensifies and subdues NUC's and SAT's.\n",
        "\n",
        "HEAVY = (1, 0).     # This weighting scheme will simply remove any significants of satelliting spans.\n",
        "LIGHT = (1.5, 0.5)  # This weighting scheme will add 50% to the nuclei, and subtract 50% from thr satellites.\n",
        "STAGE_2 = (1, 1)    # THis weighting scheme will preserve the natural weights formed from the tree.\n",
        "\n",
        "# Recursively weight the the tuple-tree (nested tuples). \n",
        "def weight_RST(weights, tup_obj, weight=1, weighting_scheme=LIGHT):\n",
        "    # print (\"Begin Weighting Process....\")\n",
        "    NUC = '[N]'\n",
        "    SAT = '[S]'\n",
        "    NA  = 'n/a'\n",
        "    relation = tup_obj[0]\n",
        "    subtree = tup_obj[1]\n",
        "    relation_type = re.findall(r'\\[[a-zA-Z]\\]', relation)\n",
        "\n",
        "    if relation == NA:\n",
        "        weights.append([subtree[0], weighting_scheme[0]])\n",
        "        return\n",
        "\n",
        "    if isinstance(subtree[0], str):\n",
        "        if relation_type[0] == NUC:\n",
        "            weights.append ([subtree[0], weight*weighting_scheme[0]])\n",
        "        if relation_type[0] == SAT:\n",
        "            weights.append ([subtree[0], weight*weighting_scheme[1]])\n",
        "    if isinstance(subtree[1], str):\n",
        "        if relation_type[1] == NUC:\n",
        "            weights.append ([subtree[1], weight*weighting_scheme[0]])\n",
        "        if relation_type[1] == SAT:\n",
        "            weights.append ([subtree[1], weight*weighting_scheme[1]])\n",
        "    if isinstance(subtree[1], tuple):\n",
        "        if relation_type[1] == NUC:\n",
        "            weight_RST(weights, subtree[1], weight*weighting_scheme[0])\n",
        "        if relation_type[1] == SAT:\n",
        "            weight_RST(weights, subtree[1], weight*weighting_scheme[1])\n",
        "    if isinstance(subtree[0], tuple):\n",
        "        if relation_type[0] == NUC:\n",
        "            weight_RST(weights, subtree[0], weight*weighting_scheme[0])\n",
        "        if relation_type[0] == SAT:\n",
        "            weight_RST(weights, subtree[0], weight*weighting_scheme[1])\n",
        "    # print (\"FINISHED Weighting Process....\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing RST Parsed Data\n",
        "\n"
      ],
      "metadata": {
        "id": "N88g6gRP7bIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight and Train Model\n",
        "> This section takes our RST outputs generated from HILDA (RST Parser) and weights the most important parts by means of a weighting scheme.\n",
        ">\n",
        "> The weighting scheme determines how the nucleus (Most important span) and its satellite (The sumplimentary span) is weighted.\n",
        ">\n",
        "> Traditionally, the weighting scheme used is (1.5, 0.5) whereby, more important spans are weighted 50% more, and the less importanted spans' importance is halved."
      ],
      "metadata": {
        "id": "zb2SvmzI7rOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Representation of outputs\n",
        "\n",
        "> Below is a graph that describes which parts of the text are the most important for each instance.\n",
        "> \n",
        "> We threshold this information and use it to train our subsequent model for detection of emerging policy changing data."
      ],
      "metadata": {
        "id": "_aPAtHF4yIJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary and Conclusions"
      ],
      "metadata": {
        "id": "XTXnO8ta9Q-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Further work and Improvements\n",
        "\n",
        "**Challenges**\n",
        "1. *The first main challenge was understanding the data in such a way that I could quickly figure out which parts would be most useful in the PoC.* \n",
        "\n",
        "    Given more time, I would like to extract other parts of the data provided and explore other uses for it (beyond RegBrain and RegInsight). I find that extra-curricular activies such as these help me to better wrap my head around the possibilities.\n",
        "\n",
        "2. *Streamlining and automating RST parsing.* Ideally, when new instances are inserted into this dataset, their RST counterpart would be automatically generated and embedded."
      ],
      "metadata": {
        "id": "xeNXiAO89UA8"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "submission.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}